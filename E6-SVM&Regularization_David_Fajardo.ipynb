{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6\n",
    "\n",
    "## SVM & Regularization\n",
    "\n",
    "\n",
    "For this homework we consider a set of observations on a number of red and white wine varieties involving their chemical properties and ranking by tasters. Wine industry shows a recent growth spurt as social drinking is on the rise. The price of wine depends on a rather abstract concept of wine appreciation by wine tasters, opinion among whom may have a high degree of variability. Pricing of wine depends on such a volatile factor to some extent. Another key factor in wine certification and quality assessment is physicochemical tests which are laboratory-based and takes into account factors like acidity, pH level, presence of sugar and other chemical properties. For the wine market, it would be of interest if human quality of tasting can be related to the chemical properties of wine so that certification and quality assessment and assurance process is more controlled.\n",
    "\n",
    "Two datasets are available of which one dataset is on red wine and have 1599 different varieties and the other is on white wine and have 4898 varieties. All wines are produced in a particular area of Portugal. Data are collected on 12 different properties of the wines one of which is Quality, based on sensory data, and the rest are on chemical properties of the wines including density, acidity, alcohol content etc. All chemical properties of wines are continuous variables. Quality is an ordinal variable with possible ranking from 1 (worst) to 10 (best). Each variety of wine is tasted by three independent tasters and the final rank assigned is the median rank given by the tasters.\n",
    "\n",
    "A predictive model developed on this data is expected to provide guidance to vineyards regarding quality and price expected on their produce without heavy reliance on volatility of wine tasters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_r = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_red.csv')\n",
    "data_w = pd.read_csv('https://github.com/albahnsen/PracticalMachineLearningClass/raw/master/datasets/Wine_data_white.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.41</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.084</td>\n",
       "      <td>59.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.99930</td>\n",
       "      <td>3.18</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.41</td>\n",
       "      <td>15.4</td>\n",
       "      <td>0.050</td>\n",
       "      <td>55.0</td>\n",
       "      <td>191.0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>8.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>11.3</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.45</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.082</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.99880</td>\n",
       "      <td>2.94</td>\n",
       "      <td>0.66</td>\n",
       "      <td>9.2</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3748</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.25</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.055</td>\n",
       "      <td>47.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>0.99758</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.51</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4591</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.042</td>\n",
       "      <td>21.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>0.99435</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "620             6.5              0.46         0.41            16.8      0.084   \n",
       "1356            7.3              0.22         0.41            15.4      0.050   \n",
       "5565           11.3              0.34         0.45             2.0      0.082   \n",
       "3748            6.2              0.24         0.25            12.5      0.055   \n",
       "4591            7.0              0.33         0.78             9.9      0.042   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "620                  59.0                 222.0  0.99930  3.18       0.58   \n",
       "1356                 55.0                 191.0  1.00000  3.32       0.59   \n",
       "5565                  6.0                  15.0  0.99880  2.94       0.66   \n",
       "3748                 47.0                 134.0  0.99758  3.30       0.51   \n",
       "4591                 21.0                 251.0  0.99435  3.01       0.55   \n",
       "\n",
       "      alcohol  quality   type  \n",
       "620       9.0        5  white  \n",
       "1356      8.9        6  white  \n",
       "5565      9.2        6    red  \n",
       "3748      9.0        5  white  \n",
       "4591     11.0        6  white  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_w.assign(type = 'white')\n",
    "\n",
    "data = data.append(data_r.assign(type = 'red'), ignore_index=True)\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.1\n",
    "\n",
    "Show the frecuency table of the quality by type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>white</td>\n",
       "      <td>4898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>red</td>\n",
       "      <td>1599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Type  Count\n",
       "0  white   4898\n",
       "1    red   1599"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.value_counts(data.type).to_frame().reset_index()\n",
    "freq.columns = ['Type','Count']\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.2\n",
    "\n",
    "* Standarized the features (not the quality)\n",
    "* Create a binary target for each type of wine\n",
    "* Create two Linear SVM's for the white and red wines, repectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standarize the features (not the quality)\n",
    "\n",
    "data['quality_bool'] = data['quality'] > 6\n",
    "#data_r['quality_bool'] = data_r['quality'] > 6\n",
    "#data_w['quality_bool'] = data_w['quality'] > 6\n",
    "datared = data[data['type'] == 'red']\n",
    "datawhite = data[data['type'] == 'white']\n",
    "\n",
    "y = data['quality_bool']\n",
    "X = data.drop(['quality_bool', 'type', 'quality'],1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss1 = StandardScaler(with_mean=True, with_std=True)\n",
    "ss1.fit(X.astype(np.float))\n",
    "X = ss1.transform(X.astype(np.float))\n",
    "#ss.mean_, ss.scale_\n",
    "\n",
    "y_red = datared['quality_bool']\n",
    "X_red = datared.drop(['quality_bool', 'type', 'quality'],1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss2 = StandardScaler(with_mean=True, with_std=True)\n",
    "ss2.fit(X_red.astype(np.float))\n",
    "X_red = ss2.transform(X_red.astype(np.float))\n",
    "#ss.mean_, ss.scale_\n",
    "\n",
    "y_white = datawhite['quality_bool']\n",
    "X_white = datawhite.drop(['quality_bool', 'type', 'quality'],1)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "ss3 = StandardScaler(with_mean=True, with_std=True)\n",
    "ss3.fit(X_white.astype(np.float))\n",
    "X_white = ss3.transform(X_white.astype(np.float))\n",
    "#ss.mean_, ss.scale_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>type</th>\n",
       "      <th>quality_bool</th>\n",
       "      <th>type_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "      <td>white</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality   type  quality_bool  type_bin  \n",
       "0      8.8        6  white         False         1  \n",
       "1      9.5        6  white         False         1  \n",
       "2     10.1        6  white         False         1  \n",
       "3      9.9        6  white         False         1  \n",
       "4      9.9        6  white         False         1  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a binary target for each type of wine\n",
    "data['type_bin'] = data['type'].replace({'white':1, 'red':0})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create two Linear SVM's for the white and red wines, repectively\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_white = SVC(kernel= 'linear')\n",
    "svm_white.fit(X_white,y_white)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_red = SVC(kernel= 'linear')\n",
    "svm_red.fit(X_red,y_red)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.3\n",
    "\n",
    "Test the two SVM's using the different kernels (‘poly’, ‘rbf’, ‘sigmoid’)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scores for the white wine SVM using the different kernels are  poly: 0.8164556962025317 rbf: 0.8397305022458146 sigmoid: 0.7354022049816251\n",
      "The scores for the red wine SVM using the different kernels are  poly: 0.9061913696060038 rbf: 0.8993120700437773 sigmoid: 0.8186366479049406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# SVM for white wines\n",
    "\n",
    "svm_white_poly = SVC(kernel= 'poly')\n",
    "svm_white_poly.fit(X_white,y_white)\n",
    "score_white_poly = svm_white_poly.score(X_white,y_white)\n",
    "\n",
    "svm_white_rbf = SVC(kernel= 'rbf')\n",
    "svm_white_rbf.fit(X_white,y_white)\n",
    "score_white_rbf = svm_white_rbf.score(X_white,y_white)\n",
    "\n",
    "svm_white_sigmoid = SVC(kernel= 'sigmoid')\n",
    "svm_white_sigmoid.fit(X_white,y_white)\n",
    "score_white_sigmoid = svm_white_sigmoid.score(X_white,y_white)\n",
    "\n",
    "# SVM for red wines\n",
    "\n",
    "svm_red_poly = SVC(kernel= 'poly')\n",
    "svm_red_poly.fit(X_red,y_red)\n",
    "score_red_poly = svm_red_poly.score(X_red,y_red)\n",
    "\n",
    "svm_red_rbf = SVC(kernel= 'rbf')\n",
    "svm_red_rbf.fit(X_red,y_red)\n",
    "score_red_rbf = svm_red_rbf.score(X_red,y_red)\n",
    "\n",
    "svm_red_sigmoid = SVC(kernel= 'sigmoid')\n",
    "svm_red_sigmoid.fit(X_red,y_red)\n",
    "score_red_sigmoid = svm_red_sigmoid.score(X_red,y_red)\n",
    "\n",
    "print('The scores for the white wine SVM using the different kernels are ','poly:', score_white_poly,'rbf:', score_white_rbf,'sigmoid:', score_white_sigmoid   )\n",
    "print('The scores for the red wine SVM using the different kernels are ','poly:', score_red_poly,'rbf:', score_red_rbf,'sigmoid:', score_red_sigmoid   )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.4\n",
    "Using the best SVM find the parameters that gives the best performance\n",
    "\n",
    "'C': [0.1, 1, 10, 100, 1000], 'gamma': [0.01, 0.001, 0.0001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1, 0.01, 0.7835851367905268], [0.1, 0.001, 0.7835851367905268], [0.1, 0.0001, 0.7835851367905268], [1, 0.001, 0.7835851367905268], [1, 0.0001, 0.7835851367905268], [10, 0.001, 0.7835851367905268], [10, 0.0001, 0.7835851367905268], [100, 0.0001, 0.7835851367905268], [1000, 0.0001, 0.7835851367905268], [1, 0.01, 0.8007349938750511], [100, 0.001, 0.8064516129032258], [1000, 0.001, 0.8182931808901592], [10, 0.01, 0.819314005716619], [100, 0.01, 0.8344222131482237], [1000, 0.01, 0.8468762760310331]]\n",
      "[[0.1, 0.01, 0.8642901813633521], [0.1, 0.001, 0.8642901813633521], [0.1, 0.0001, 0.8642901813633521], [1, 0.01, 0.8642901813633521], [1, 0.001, 0.8642901813633521], [1, 0.0001, 0.8642901813633521], [10, 0.001, 0.8642901813633521], [10, 0.0001, 0.8642901813633521], [100, 0.001, 0.8642901813633521], [100, 0.0001, 0.8642901813633521], [1000, 0.001, 0.8642901813633521], [1000, 0.0001, 0.8642901813633521], [10, 0.01, 0.8655409631019387], [100, 0.01, 0.8799249530956847], [1000, 0.01, 0.9105691056910569]]\n",
      "La mejor combinacion para ambos tipos es c=1000 y gamma=0.01\n"
     ]
    }
   ],
   "source": [
    "white_list = []\n",
    "red_list = []\n",
    "\n",
    "for c in [0.1, 1, 10, 100, 1000]:\n",
    "    for g in [0.01, 0.001, 0.0001]:\n",
    "        svm_white_rbf = SVC(kernel= 'rbf',C=c, gamma=g)\n",
    "        svm_white_rbf.fit(X_white,y_white)\n",
    "        white_list.append([c,g,svm_white_rbf.score(X_white,y_white)]) \n",
    "        svm_red_poly = SVC(kernel= 'poly',C=c, gamma=g)\n",
    "        svm_red_poly.fit(X_red,y_red)\n",
    "        red_list.append([c,g, svm_red_poly.score(X_red,y_red)])\n",
    "\n",
    "white_list.sort(key=lambda x: x[2]) \n",
    "red_list.sort(key=lambda x: x[2]) \n",
    "print(white_list)\n",
    "print(red_list)\n",
    "print(\"La mejor combinacion para ambos tipos es c=1000 y gamma=0.01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.5\n",
    "\n",
    "Compare the results with other methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Reg. for white, accuracy: 0.8017558187015108\n",
      "Logistic Reg. for red, accuracy: 0.7986241400875547\n",
      "SVM es mejor para los dos tipos de vino:  \n",
      "white_SVM=0.85 vs white_LOGIT=0.8\n",
      "red_SVM=0.91 vs white_LOGIT=0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "reg_white = linear_model.LogisticRegression()\n",
    "reg_white.fit(X_white,y_white)\n",
    "\n",
    "reg_red = linear_model.LogisticRegression()\n",
    "reg_red.fit(X_red,y_red)\n",
    "\n",
    "predictions_white = reg_white.predict(X_white)\n",
    "predictions_red = reg_white.predict(X_red)\n",
    "print(\"Logistic Reg. for white, accuracy:\", accuracy_score(y_white, predictions_white))\n",
    "print(\"Logistic Reg. for red, accuracy:\",accuracy_score(y_red, predictions_red))\n",
    "\n",
    "print('''SVM es mejor para los dos tipos de vino:  \n",
    "white_SVM=0.85 vs white_LOGIT=0.8\n",
    "red_SVM=0.91 vs white_LOGIT=0.7986''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.6\n",
    "\n",
    "\n",
    "* Train a linear regression to predict wine quality (Continous)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11887781, -0.27826199, -0.00759825,  0.33225392, -0.02617215,\n",
       "        0.10735663, -0.10596155, -0.33067241,  0.08229493,  0.1250517 ,\n",
       "        0.31047882, -0.16917504])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "lr_X = X\n",
    "lr_y = data['quality']\n",
    "\n",
    "#Standarize y\n",
    "y_mean, y_std = lr_y.mean(), lr_y.std()\n",
    "lr_y = (lr_y - y_mean)/ y_std\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(lr_X, lr_y, test_size=0.2, random_state=42)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7867684897961288\n"
     ]
    }
   ],
   "source": [
    "#RMSE\n",
    "from sklearn import metrics\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test,y_pred )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.7\n",
    "\n",
    "* Estimate a ridge regression with alpha equals 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with alpha 0.1: 0.7867697144798156\n"
     ]
    }
   ],
   "source": [
    "# Ridge\n",
    "from sklearn.linear_model import Ridge\n",
    "ridgereg01 = Ridge(alpha=0.1)\n",
    "ridgereg01.fit(X_train, y_train)\n",
    "y_pred01 = ridgereg01.predict(X_test)\n",
    "print('RMSE with alpha 0.1:', np.sqrt(metrics.mean_squared_error(y_test,y_pred01 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with alpha 1: 0.7867807516615621\n"
     ]
    }
   ],
   "source": [
    "ridgereg1 = Ridge(alpha=1)\n",
    "ridgereg1.fit(X_train, y_train)\n",
    "y_pred1 = ridgereg1.predict(X_test)\n",
    "print('RMSE with alpha 1:', np.sqrt(metrics.mean_squared_error(y_test,y_pred1 )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.8\n",
    "\n",
    "* Estimate a lasso regression with alpha equals 0.01, 0.1 and 1.\n",
    "* Compare the coefficients with the linear regression\n",
    "* Evaluate the RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with alpha 0.01: 0.792323218765886\n"
     ]
    }
   ],
   "source": [
    "# Lasso\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lassoreg001 = Lasso(alpha=0.01)\n",
    "lassoreg001.fit(X_train, y_train)\n",
    "y_pred001 = lassoreg001.predict(X_test)\n",
    "print('RMSE with alpha 0.01:', np.sqrt(metrics.mean_squared_error(y_test,y_pred001 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with alpha 0.1: 0.8214188635497301\n"
     ]
    }
   ],
   "source": [
    "lassoreg01 = Lasso(alpha=0.1)\n",
    "lassoreg01.fit(X_train, y_train)\n",
    "y_pred01 = lassoreg01.predict(X_test)\n",
    "print('RMSE with alpha 0.1:', np.sqrt(metrics.mean_squared_error(y_test,y_pred01 )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE with alpha 1: 0.9681743922374527\n"
     ]
    }
   ],
   "source": [
    "lassoreg1 = Lasso(alpha=1)\n",
    "lassoreg1.fit(X_train, y_train)\n",
    "y_pred1 = lassoreg1.predict(X_test)\n",
    "print('RMSE with alpha 1:', np.sqrt(metrics.mean_squared_error(y_test,y_pred1 )))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.9\n",
    "\n",
    "* Create a binary target\n",
    "\n",
    "* Train a logistic regression to predict wine quality (binary)\n",
    "\n",
    "* Analyze the coefficients\n",
    "\n",
    "* Evaluate the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.8184615384615385 , which means this model has a good accuracy.\n",
      "The f1 score is 0.34806629834254144 which means the model wouldn't be the best, the closer to 1 the better.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/davidfajardo/anaconda3/lib/python3.5/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#Create a binary target\n",
    "y = data['quality_bool']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "reg = linear_model.LogisticRegression()\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "\n",
    "lr.coef_\n",
    "\n",
    "print('The accuracy score is',accuracy_score(y_test, y_pred),', which means this model has a good accuracy.')\n",
    "print('The f1 score is',f1_score(y_test, y_pred), 'which means the model wouldn\\'t be the best, the closer to 1 the better.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6.10\n",
    "\n",
    "* Estimate a regularized logistic regression using:\n",
    "* C = 0.01, 0.1 & 1.0\n",
    "* penalty = ['l1, 'l2']\n",
    "* Compare the coefficients and the f1score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01, 'l1', 0.24281150159744405], [0.01, 'l2', 0.3285302593659943], [0.1, 'l1', 0.32386363636363635], [0.1, 'l2', 0.3388888888888889], [1, 'l1', 0.34349030470914127], [1, 'l2', 0.34806629834254144]]\n",
      "La mejor combinacion para ambos tipos es c=1000 y gamma=0.01\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for c in [0.01, 0.1, 1]:\n",
    "    for p in ['l1', 'l2']:\n",
    "        logreg = linear_model.LogisticRegression(C=c, penalty = p, solver='liblinear',multi_class='auto')\n",
    "        logreg.fit(X_train,y_train)\n",
    "        y_pred = logreg.predict(X_test)   \n",
    "        results.append([c,p,f1_score(y_test, y_pred)])\n",
    "\n",
    "print(results)\n",
    "print(\"La mejor combinacion para ambos tipos es c=1 y penalty=l2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
